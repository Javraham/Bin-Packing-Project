{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f21658-40c8-40c9-99d2-ec8c0b42e84f",
   "metadata": {},
   "source": [
    "# Bin Packing Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffdec9-9fcb-4a7b-910e-abecc6352210",
   "metadata": {},
   "source": [
    "- Authors:\n",
    "  - Daniel Akselrod, akselrod@mcmaster.ca\n",
    "  - Jonathan Avraham, avrahamj@mcmaster.ca\n",
    "- Group ID on Avenue: binpack 51\n",
    "- Gitlab URL: https://gitlab.cas.mcmaster.ca/akselrod/l2-bin-packing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a2de3",
   "metadata": {},
   "source": [
    "### Task 1: Understand the Code Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dfac1f",
   "metadata": {},
   "source": [
    "#### SOLID Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b959c",
   "metadata": {},
   "source": [
    "This code follows the SOLID principle as follows:\n",
    "\n",
    "Single-Responsibility Principle: This principle states that each class or function should really only be doing one job. This means that\n",
    "the class should only contain variables and methods that are related to its job. We can clearly see this in the initial code is given. \n",
    "For example, each algorithm is given its only class and method where its job is just to ouput a given solution. It does not contain\n",
    "any variables that do not belong to its functionality and only focuses on evaluating a specific task. Each reader is also given its own\n",
    "class where its job is just to read a given dataset, whether it is the BPP or jburkardt dataset, it is made with different classes to \n",
    "comply with the Single-Responsibility principle.\n",
    "\n",
    "Open-Close Principle: This principle states that entities should be open for extension but closed for modification. This means that we \n",
    "will extend a parent class instead of modifying it. This is shown clearly in the UML diagram and classes given. We do not want to modify\n",
    "the Datasetreader class in order to add a new reader, instead we extend that class to add a reader that is needed. This is also shown \n",
    "through our implemented algorithms. Instead of adding new methods to the online or offline class, we would rather have extensions of \n",
    "the class to implement the algorithms to follow this principle. \n",
    "\n",
    "Liskov Substitution Principle: This principle states that parent classes should be easily substituted with their subclasses without\n",
    "getting any error. This would not occur in the code given as our parent classes are able to be called as its child classes without changing\n",
    "the correctness of the program or crashing it.\n",
    "\n",
    "Dependancy-inversion principle: This principle states that entites should depend on abstractions, not concretions. This means high level \n",
    "modules should not depend on low level modules, rather they both depend on an abstract class. This is clearly shown in this code where\n",
    "the \"readers\" depend on the abstract method \"_load_data_from_disk\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2893caf1",
   "metadata": {},
   "source": [
    "#### Data Set Dimension Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e26acb",
   "metadata": {},
   "source": [
    "The first dataset represents the BPP dataset. This dataset conatins parameters 'n' which represents the number of items or weights that need\n",
    "to be packed into bins, 'c' which is the total capacity of each bin, and 'w[j]' which is the weight of each object where [j] is \n",
    "in the range of 'n'. The weight of the object is in the range of [1, 'c']. The values for 'c' can only be numbers 100, 120 or 150 and the \n",
    "values of 'n' can only be 50, 100, 200 or 500. The naming convention of each folder in the BPP dataset represents exactly what the \n",
    "'c', 'n', and the range of 'w' is which is a great way to organize and determine exactly what can be benchmarked or tested. The reader reads\n",
    "the second row of the dataset as the capacity and iterates through each weight after that with an Iterator. The second dataset is the \n",
    "BPP-Hard dataset which acts the same way as the BPP dataset, however, has way larger values for its parameters. In contrast to the BPP dataset,\n",
    "this one has a bin capacity of 10000 and has 200 objects/weights that need to be packed into bins. To accomadate for the high capacity,\n",
    "each weight has a value that ranges from (20000, 35000). This dataset is great for evaluating algorithms on a larger scale in comparison to\n",
    "the BPP dataset which has smaller values, in addition to guarenteeing that the weights are widely spread out. The third dataset is the \n",
    "jburkardt dataset which is composed of three files for each case. The first file contains the capacity of each bin, the second file conatins\n",
    "the solution of binpacking, which states which weight will be put in which bin, and the third file is the list of weights that need to be \n",
    "packed. This is great way for evaluating algorithms as we are able to compare the optimal solution to the different algorithms that we are\n",
    "implementing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a2de3",
   "metadata": {},
   "source": [
    "### Task 2: Implement and Benchmark Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41682abd",
   "metadata": {},
   "source": [
    "#### Solution comparison\n",
    "\n",
    "There can exist many solutions to a given bin-packing problem. These can be developed from various algorithms or even random arangements of items. However, in some cases, some solutions can be deemed more optimal by others. For example, one problem may prefer a solution with non-nearly full bins at the cost of having more bins. For example, a real life application may look at internet servers. As servers can only handel so much traffic, hosting only a few servers that can reach full capacity versus more servers that are more empty could bring forwards solutions with more bins and more remaining capacities per bin. Another KPI depending on the situation can be how balanced the bin sizes are. This is also a feature that a server host may look for as balancing out traffic portals can lead to stronger connections giving servers an easier time.\n",
    "\n",
    "Below is a class that is capable of returning multiple properties of given a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0a0c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Empty Space:  13\n",
      "Average weight per bin:  5.666666666666667\n",
      "Average number of weights per bin:  2.0\n",
      "Total sum of all weights in solution:  17\n"
     ]
    }
   ],
   "source": [
    "class SolutionAnalyzer:\n",
    "    def __init__(self, solution, capacity):\n",
    "        self.bins = solution\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def GetNumBins(self):\n",
    "        return len(self.bins)\n",
    "\n",
    "    def GetAvgNumWeightsPerBin(self):\n",
    "        return sum([len(bin) for bin in self.bins])/len(self.bins)\n",
    "\n",
    "    def CalculateEmptySpace(self):\n",
    "        return sum([self.capacity - sum(bin) for bin in self.bins])\n",
    "\n",
    "    def CalculateAverageCapacity(self):\n",
    "        return sum([sum(bin) for bin in self.bins])/len(self.bins)\n",
    "\n",
    "    def CalculateAggregateBinWeight(self):\n",
    "        return sum([sum([weight for weight in bin]) for bin in self.bins])\n",
    "\n",
    "s = SolutionAnalyzer([[1,2],[3,4],[3,4]], 10)\n",
    "print(\"Total Empty Space: \", s.CalculateEmptySpace())\n",
    "print(\"Average weight per bin: \", s.CalculateAverageCapacity())\n",
    "print(\"Average number of weights per bin: \", s.GetAvgNumWeightsPerBin())\n",
    "print(\"Total sum of all weights in solution: \", s.CalculateAggregateBinWeight())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf1e3f",
   "metadata": {},
   "source": [
    "#### Algorithm Benchmarks\n",
    "\n",
    "Through benchmarking various algorithms against different data sets, it can be seem that some algorithms give better run time versus others. This is due to how complex the algorithms are when they fill bins. An online next fit algorhtm just throws items in the bins as they come along and doesn't really care about the amount of space its leaving behind. However, on the contrary, a best fit algorithm tries to minimize the amount of empty space in every bin and thus is more computationally heavy resulting in a longer runtime. \n",
    "\n",
    "For the dataset N4C2W2_A, the next fit online algorithm average an execution time of around 200 nanoseconds where as the offline best fit algorithm has an execution time of around 600 nanoseconds.\n",
    "\n",
    "The most complex algorithm, the refined first fit algorithm, which classifies bins based on the weights they hold has an average runntime of 400 nanoseconds per data set. The reason why the offline best fit algorithm is slower is because it first is concerned with sorting the data, but after runs more simply.t fit algorithm has an execution time of around 600 nanoseconds.\n",
    "\n",
    "The most complex algorithm, the refined first fit algorithm, which classifies bins based on the weights they hold has an average runntime of 400 nanoseconds per data set. The reason why the offline best fit algorithm is slower is because it first is concerned with sorting the data, but after runs more simply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234f9c12",
   "metadata": {},
   "source": [
    "#### Benchmark Results\n",
    "\n",
    "<img src=\"benchmarking/benchmark_histograms/BestFitOffline_N4C2W2_A.png\" width=400 height=400 />\n",
    "<img src=\"benchmarking/benchmark_histograms/BestFitOnline_N4C2W2_A.png\" width=400 height=400 />\n",
    "<img src=\"benchmarking/benchmark_histograms/WorstFitOffline_N4C2W2_A.png\" width=400 height=400 />\n",
    "<img src=\"benchmarking/benchmark_histograms/WorstFitOnline_N4C2W2_A.png\" width=400 height=400 />\n",
    "<img src=\"benchmarking/benchmark_histograms/NextFitOffline_N4C2W2_A.png\" width=400 height=400 />\n",
    "<img src=\"benchmarking/benchmark_histograms/NextFitOnline_N4C2W2_A.png\" width=400 height=400 />\n",
    "<img src=\"benchmarking/benchmark_histograms/FirstFitOffline_N4C2W2_A.png\" width=400 height=400 />\n",
    "<img src=\"benchmarking/benchmark_histograms/FirstFitOnline_N4C2W2_A.png\" width=400 height=400 />\n",
    "<img src=\"benchmarking/benchmark_histograms/RefFirstFitOnline_N4C2W2_A.png\" width=400 height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56691b47",
   "metadata": {},
   "source": [
    "### Task 3: Measure Imrpovement Margin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce93d44",
   "metadata": {},
   "source": [
    "#### Optimal Solutions Comparison\n",
    "\n",
    "Using our various algorithms, our best solutions were compared with the most optimal solution for 10 sampled in the HARD-BPP dataset. In all tests, our solution produced about 3-4 more bins than the optimal. This can be seen in the graph below.\n",
    "\n",
    "<img src=\"NumBinsComparison.png\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e416b1",
   "metadata": {},
   "source": [
    "### Task 4: Add Smarted Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3888ccd",
   "metadata": {},
   "source": [
    "#### The Refined First Fit Algorithm\n",
    "\n",
    "The refind first fit algorithm works by classifying weights into respective bins. In the FirstFitAlgorithm located in the online algorithms file, objects are first classified by their weight according to an interval with in classifications including A, B1, B2, and X. Then by keeping track of what objects go into their respective bins, the bins are each classified with a number 1 to 4. Below is an enlarged graph of the bench mark of the Refined First Fit Online algorithm with the N4C2W2_A data set.\n",
    "\n",
    "<img src=\"benchmarking/benchmark_histograms/RefFirstFitOnline_N4C2W2_A.png\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e416b1",
   "metadata": {},
   "source": [
    "### Task 5: From Fixed Capacity to Fixed Bons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e1a9e6",
   "metadata": {},
   "source": [
    "#### Multiway Number Partitioning\n",
    "\n",
    "As mentioned previously, it is sometimes less important to care about the number of bins that a solution uses, but rather how the objects are balanced throughout these bins. The to_constant_bin_number() keeps the bin numbers constant while trying to best manage the objects and organize a solution with the most balanced bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "621e5280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6], [5], [4, 1], [3, 2]]\n"
     ]
    }
   ],
   "source": [
    "from binpacking import to_constant_bin_number\n",
    "\n",
    "weights = [1,2,3,4,5,6]\n",
    "capacity = 10\n",
    "num_bins = 4\n",
    "\n",
    "def BalancedBins(stream, num_bins):\n",
    "    return to_constant_bin_number(stream, num_bins)\n",
    "\n",
    "print(BalancedBins(weights, num_bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399bc65",
   "metadata": {},
   "source": [
    "As seen in the function above, the sample shows the bins balanced to being a total weight of 5 or 6 per bin with 4 bins being used as specified in the to_constant_bin_number() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e027d",
   "metadata": {},
   "source": [
    "#### KPI Analysis\n",
    "\n",
    "Although the to_constant_bin_number() method works, it is unfair to judge its performance with the same KPI's that were used previously. This is because we no longer care about the amount of bins.\n",
    "\n",
    "However, KPI's that worried about the contents per bin can still be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217aefb9-4bf5-4975-9e18-95718b2c47ca",
   "metadata": {},
   "source": [
    "### Self-reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06d84a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Jonathan's Self Reflection\n",
    "\n",
    "1) In order to produce the outcome of the lab, there initially needed to be a lot of research done on the algorithms and topics explored.\n",
    "Even before this step, I proficiently needed to go through the entire code base and made sure I understood every detail of the UML and \n",
    "what is presented in front of me as I would need to utilize the resources given to formulate a good solution. After going through the code \n",
    "base, I immediatly did research on bin packing and how to implement the algorithms in simple terms. Later, I needed to expand my knowledge\n",
    "and work with Object-Oriented Programming in order to apply the algorithms using classes and objects. This is done for cleaner code and \n",
    "comply with the SOLID principles more efficiently. I later needed to do more research on how to properly benchmark and optimize the way\n",
    "benchmarking is done in order to produce the most optimal results. The same was done when making the tests for each algorithm. \n",
    "\n",
    "2) My standards for this piece of work was to learn how to properly benchmark and test algorithms, in addition to comparing the results in\n",
    "order to obtain an optimal solution. The part where we needed to implement the algorithms themselves was not as important to me as the\n",
    "actual benchmarking and testing, since implementing algorithms is something I am a little more proficient in. My standard was more to \n",
    "understand the benchmarking and implement them properly in order to obtain a set of results that are usefule for me to analyze. This part of \n",
    "the process definitely took the longest, however, I can say that my standards were clearly met as the group was able to implement them in many\n",
    "efficient ways. \n",
    "\n",
    "3) One thing I would want people to notice about the completed lab is how the testing was done and how OOP was incorporated when \n",
    "implementing algorithms and the benchmarks. For example, A class was made for benchmark which was instatiated whenever we wanted to make\n",
    "a benchmark for a specific case or type of algorithm. This was a great way of implemenation as it reduces duplication of code and is more\n",
    "readable to the user. In addition, instead of using arrays for bins, objects and dealing with operation on those arrays, we made classes\n",
    "for Bins and Objects that hold certain attributes, and performed the Refined First Fit algorithm with those. This made making the Refined\n",
    "Fit Algorithm a lot easier as using classes is a lot more organized and readable to the user. The way the tests were done for each Algorithm\n",
    "is also something I would like to people to notice as many cases were added, including boundary cases, and are very useful to ensure\n",
    "that the code actually works before benchmarking and analyzing them.\n",
    "\n",
    "4) A part of this lab that I learned and will take with me to my professional practice is how code needs to be implemeneted to ensure\n",
    "readability and understanding. The use of OOP in this assignment is something that I learned to do a lot better and really helped out\n",
    "when writing the algorithms. This is because when writing clean code with OOP, and using classes within other classes, it really helps with\n",
    "debugging code and we are no longer relying on a huge function when making changes. As long as the class it written correctly, whenever\n",
    "we have an error in another method, we know its something that was changed in that method and not in the class itself. Therefore, how to\n",
    "implement clean code and understanding what each code section does it key to getting the results I need in the professional practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67d80c9",
   "metadata": {},
   "source": [
    "#### Daniel's Self Reflection\n",
    "\n",
    "1) The process I had to go through in order to get the appropriate results, started with just understanding the code base. The first part of the code base that I examined was the UML diagram, to have a general idea of what is already given and how to implement the other classes and algorithms with extension of the classes provided. After examining the code base, I started looking into different ways to benchmark the algorithms given before even implementing the algorithms. After finding many solutions to this and a considerable amount of time, I had finally come up with a quick and efficient way to do this. \n",
    "\n",
    "2) My standards for this piece of work was to properly implement the algorithms and general code using OOP while maintaining the SOLID principles, as I believe it is extremely important to write code that others can understand and modify without crashing the entire module. Another standard that I had for this piece of work was retrieving results from benchmarks that are easy to analyze and compare when looking at the different implementations. As seen within the different packages and classes, my standard was met for implementing proper object- oriented code that is readable to me and hopefully to others, however, the results retrieved from benchmarks was a little harder to work with and analyze. Nonetheless, my overall standard was exactly what I expected from the start which was great. \n",
    "\n",
    "3) One part of my work that I would want people to look at is how I implemented OOP code and how everything was synced together using modules and packages. The part of the lab that definitely blew my mind the most is how I managed to properly put everything together , whether it came to benchmarking, tests, or algorithms using packages and modules. Using OOP design, I was really satisfied when I was able to make classes for bins and objects and utilize them within the algorithms that were implemented. This is something I would really want people to notice when examining this piece of work as clean code and proper OOP design is an aspect of coding that is very important to me. \n",
    "\n",
    "4) The primary lesson that I learned from this reading are the steps that need to be taken in order to obtain proper results in any project or lab in the future. Research and using the resources available to you is key before attempting something that is difficult to do. This lab really taught me how to properly start executing a lab so that the amount of times you encounter something difficult is minimal. For example, understanding how to use pyperf when benchmarking and plotting graphs was a huge aspect of the lab where we needed to compare and analyze data. Researching this beforehand and understanding the concept at hand was a crucial step for me to accomplish this task with ease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "841e984a602cdb5097f1c299b26a943b91a41bebfa66b38188d4eb424ee9358e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
